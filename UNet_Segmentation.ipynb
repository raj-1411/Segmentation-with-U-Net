{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhgLQ9PfNSt3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from skimage.io import imread \n",
        "from PIL import Image\n",
        "import csv\n",
        "import torch\n",
        "import copy\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils import data\n",
        "import torchvision.transforms as transf\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.transforms import RandomAdjustSharpness\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from torch import optim\n",
        "from torch.nn.modules.conv import ConvTranspose2d\n",
        "from torch.autograd import Function\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3JzeIYw95ZC"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1vVTRnU5GBX"
      },
      "source": [
        "# Your dataset's path and preprocessing\n",
        "\n",
        "Structure of dataset should be as following:\n",
        "\n",
        "--- /input ------/image1.png ------/image2.png ------/image3.png\n",
        "...\n",
        "\n",
        "--- /target ------/mask1.png ------/mask2.png ------/mask3.png\n",
        "...\n",
        "\n",
        "Dataset pipeline --- ordered list of corresponding images and mask paths ---\n",
        "\n",
        "img_list --> ['image1.png', 'image2.png', 'image3.png',...]\n",
        "\n",
        "msk_list --> ['mask1.png', 'mask2.png', 'mask3.png',...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi8ZjN9-KSRl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUVZape1oohP"
      },
      "source": [
        "Dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nfSrw5mFiDJ"
      },
      "outputs": [],
      "source": [
        "class SegDataset(data.Dataset):\n",
        "  \n",
        "  def __init__(self, img_list, msk_list, transform=None):\n",
        "    self.img_list = img_list\n",
        "    self.msk_list = msk_list\n",
        "    self.transforms = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n",
        "\n",
        "  @classmethod\n",
        "  def preprocess(self,pil_img, size):\n",
        "    # w,h = pil_img.size\n",
        "    # W,H = int(scale*w), int(scale*h)\n",
        "    pil_img = pil_img.resize((size,size))\n",
        "\n",
        "    img_nd = np.array(pil_img)\n",
        "\n",
        "    if len(img_nd.shape) == 2:\n",
        "      img_nd = np.expand_dims(img_nd, axis=2)\n",
        "\n",
        "    '''if tranforms are present paste them here'''\n",
        "\n",
        "    #HWC to CHW\n",
        "    img_trans = img_nd.transpose((2,0,1))\n",
        "    if img_trans.max() > 1:\n",
        "      img_trans = img_trans/225\n",
        "\n",
        "    return img_trans\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_ID = self.img_list[index]\n",
        "    target_ID = self.msk_list[index]\n",
        "\n",
        "    img = Image.open(input_ID)\n",
        "    msk = Image.open(target_ID)\n",
        "\n",
        "    ''' \n",
        "    assert img.size == msk.size, \\\n",
        "    f'Image and mask for {index} should be the same, but are {img.size} and {msk.size}'\n",
        "    '''\n",
        "    # preprocessing\n",
        "    img = self.preprocess(img, 224)\n",
        "    msk = self.preprocess(msk, 216)\n",
        "    \n",
        "    return {\n",
        "        'image': torch.from_numpy(img).type(torch.FloatTensor),\n",
        "        'mask': torch.from_numpy(msk).type(torch.FloatTensor)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTx5mtfsK_Bc"
      },
      "outputs": [],
      "source": [
        "input_tr = glob.glob('/content/drive/MyDrive/PH2/train/input/*')\n",
        "input_val = glob.glob('/content/drive/MyDrive/PH2/val/input/*')\n",
        "\n",
        "target_tr = [element[:-16]+'target'+element[-11:-4]+'_lesion'+element[-4:] for element in input_tr]\n",
        "target_val = [element[:-16]+'target'+element[-11:-4]+'_lesion'+element[-4:] for element in input_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhDUdBpqsP2K"
      },
      "outputs": [],
      "source": [
        "input_tr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHTQVkuo5tMO"
      },
      "source": [
        "# Hyperparameter Tuning and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnSZRCggJQqU"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning\n",
        "batch_size_tr = 20\n",
        "batch_size_val = 15\n",
        "epoch_n = 200\n",
        "n_channels = 3\n",
        "n_classes = 1\n",
        "l_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2rn9A6ROcQK"
      },
      "outputs": [],
      "source": [
        "train_ds = SegDataset(input_tr, target_tr)#,transform=transforms_tr)\n",
        "val_ds = SegDataset(input_val, target_val)#,transform=transforms_val)\n",
        "# test_ds = ImageFolder('/content/drive/MyDrive/Lung_Carcinoma/data_folder_2/test/', transform=val_transform)\n",
        "train_load = DataLoader(dataset=train_ds, batch_size=batch_size_tr, shuffle=False, drop_last=False)\n",
        "val_load = DataLoader(dataset=val_ds, batch_size=batch_size_val, shuffle=False, drop_last=False)\n",
        "# test_load = DataLoader(dataset=test_ds, batch_size=batch_size_val, shuffle=True, drop_last=False)\n",
        "if torch.cuda.is_available():\n",
        "  device='cuda'\n",
        "else:\n",
        "  device='cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJTj1RFy6FS3"
      },
      "source": [
        "# Structure of U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfw_r6DwFR_L"
      },
      "outputs": [],
      "source": [
        "# Segmentation architecture\n",
        "# U-Net\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "    super().__init__()\n",
        "    if mid_channels is None:\n",
        "      mid_channels = out_channels\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, 3, 1),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(mid_channels, out_channels, 3, 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(2),\n",
        "        DoubleConv(in_channels, out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels, in_channels//2, 2, 2)\n",
        "    self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1=self.up(x1)\n",
        "    delta_W = x2.size()[3]-x1.size()[3]\n",
        "    delta_H = x2.size()[2]-x1.size()[2]\n",
        "    x1 = F.pad(x1,[delta_W//2,delta_W-delta_W//2,delta_H//2,delta_H-delta_H//2])\n",
        "    x = torch.cat([x2,x1],dim=1)\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class FinalConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_final = nn.Conv2d(in_channels, out_channels,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.conv_final(x)\n",
        "\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "  def __init__(self, in_channels, out_classes):\n",
        "    super(U_Net,self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_classes = out_classes\n",
        "\n",
        "    self.initial_conv = DoubleConv(in_channels, 64)#(N*N*64)\n",
        "    self.down1 = Down(64, 128)#(N/2*N/2*128)\n",
        "    self.down2 = Down(128, 256)#(N/4*N/4*256)\n",
        "    self.down3 = Down(256, 512)#(N/8*N/8*512)\n",
        "    self.down4 = Down(512, 1024)#(N/16*N/16*1024)\n",
        "    self.up1 = Up(1024,512)\n",
        "    # i_up = N/8*N/8*512 & i(after concatenation) --> (N/8*N/8*1024) i_final --> (N/8*N/8*512)\n",
        "    self.up2 = Up(512,256)\n",
        "    # i_up = N/4*N/4*256 & i(after concatenation) --> N/4*N/4*256*2\n",
        "    self.up3 = Up(256,128)\n",
        "    self.up4 = Up(128,64)\n",
        "    self.final = FinalConv(64, out_classes)\n",
        "    \n",
        "  \n",
        "  def forward(self,i):\n",
        "    i1 = self.initial_conv(i)\n",
        "    i2 = self.down1(i1)\n",
        "    i3 = self.down2(i2)\n",
        "    i4 = self.down3(i3)\n",
        "    i5 = self.down4(i4)\n",
        "    i = self.up1(i5,i4)\n",
        "    i = self.up2(i,i3)\n",
        "    i = self.up3(i,i2)\n",
        "    i = self.up4(i,i1)\n",
        "    i = self.final(i)\n",
        "    return torch.sigmoid(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIJ5l6vJ6Qgm"
      },
      "source": [
        "# Loss Functions (IoU Score and IoU Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCyLLrKGAhVr"
      },
      "outputs": [],
      "source": [
        "''' IoU Score '''\n",
        "\n",
        "def IoU_score(mask_gen, mask):\n",
        "  s = torch.FloatTensor(1).cuda().zero_()\n",
        "  for i,t in enumerate(zip(mask_gen, mask)):\n",
        "    s += get_IoU(t[0], t[1])\n",
        "  return s/(i+1)\n",
        "\n",
        "  # loss functions\n",
        "\n",
        "'''IoU-Loss'''\n",
        "\n",
        "def get_IoU(src, tar):\n",
        "  inter = (src*tar).sum(dim=(1,2))\n",
        "  union_inter = (src+tar).sum(dim=(1,2))\n",
        "  #print(inter, union_inter)\n",
        "  score = (inter.float()+1)/((union_inter-inter).float()+1)\n",
        "  return score\n",
        "\n",
        "def loss_iou(mask_gen, mask):\n",
        "    s=torch.FloatTensor(1).cuda().zero_()\n",
        "    for i,t in enumerate(zip(mask_gen, mask)):\n",
        "      # print(t[0].shape, t[1].shape)\n",
        "      s += get_IoU(t[0], t[1])\n",
        "    return 1-(s/(i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loss Functions (Dice Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx_FendLeJhV"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Function, Variable\n",
        "\n",
        "class DiceCoeff(Function):\n",
        "    \"\"\"Dice coeff for individual examples\"\"\"\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # target = _make_one_hot(target, 2)\n",
        "        self.save_for_backward(input, target)\n",
        "        eps = 0.0001\n",
        "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
        "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
        "        # print(\"inter,uniun:\",self.inter,self.union)\n",
        "\n",
        "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
        "        return t\n",
        "\n",
        "def dice_coeff(input, target):\n",
        "    \"\"\"Dice coeff for batches\"\"\"\n",
        "    if input.is_cuda:\n",
        "        s = torch.FloatTensor(1).cuda().zero_()\n",
        "    else:\n",
        "        s = torch.FloatTensor(1).zero_()\n",
        "\n",
        "    # print(\"size of input, target:\", input.shape, target.shape)\n",
        "\n",
        "    for i, c in enumerate(zip(input, target)):\n",
        "        s = s + DiceCoeff().forward(c[0], c[1])\n",
        "\n",
        "    return s / (i + 1)\n",
        "\n",
        "\n",
        "def dice_coeff_loss(input, target):\n",
        "    return 1 - dice_coeff(input, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6IK7r5j630X"
      },
      "source": [
        "# Model specifications and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBpS3FgJtikn"
      },
      "outputs": [],
      "source": [
        "model = U_Net(n_channels, n_classes)\n",
        "#state=torch.load('/content/drive/MyDrive/PH2/model_wts/U_Net_weights_1_IoU.pth') # ekhane previous weight ta src korbi \n",
        "#model.load_state_dict(state['model_state'])\n",
        "model = model.to(device)\n",
        "# criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(model.parameters(), l_rate)\n",
        "#optim.load_state_dict(state['optimizer_state'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEqb5JGqF4_j"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "def train(model, epoch_n, optim): #,criterion):\n",
        "  best_loss=0.0058 # ekhane previous best acc ta dibi in the format 0.XX\n",
        "  train_loss_list = []\n",
        "  val_loss_list = []\n",
        "  for epoch in range(epoch_n):\n",
        "    model.train()\n",
        "    train_loss=iou_tr=total=dice_tr=0.0\n",
        "    for _,data in enumerate(train_load):\n",
        "      image = data['image'].to(device, dtype=torch.float32)\n",
        "      mask_type = torch.float32 if n_classes == 1 else torch.long\n",
        "      mask = data['mask'].to(device, dtype=mask_type)\n",
        "      with torch.set_grad_enabled(True):\n",
        "        mask_gen = model(image)\n",
        "        loss = dice_coeff_loss(mask_gen,mask)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "      optim.zero_grad()\n",
        "      train_loss += loss.item()\n",
        "      total += mask.size(0)\n",
        "      dice_tr += dice_coeff(mask_gen, mask).item()\n",
        "      iou_tr += IoU_score(mask_gen,mask).item()\n",
        "    val_loss, iou_val, dice_val = eval(model)#, criterion)\n",
        "    epoch_train_loss = train_loss/len(train_ds)\n",
        "    print(\"Epoch: {}\".format(epoch+1))\n",
        "    print('-'*10)\n",
        "    print('Train Loss: {:.9f}'.format(epoch_train_loss))\n",
        "    epoch_val_loss = val_loss/len(val_ds)\n",
        "    print('Val Loss: {:.9f}'.format(epoch_val_loss))\n",
        "    print('\\n')\n",
        "    print('Dice score train: {:.9f}'.format(dice_tr/len(train_load)))\n",
        "    print('\\n')\n",
        "    print('Dice score val: {:.9f}'.format(dice_val/len(val_load)))\n",
        "    print('\\n')\n",
        "    print('IoU score train: {:.9f}'.format(iou_tr/len(train_load)))\n",
        "    print('\\n')\n",
        "    print('IoU score val: {:.9f}'.format(iou_val/len(val_load)))\n",
        "    print('\\n')\n",
        "    plt.imshow(mask_gen.cpu().detach().numpy()[-9][0])\n",
        "    _, axarr = plt.subplots(1,3)\n",
        "    axarr[0] = plt.imshow(image.cpu().detach().numpy()[-9].transpose((1,2,0)))\n",
        "    if best_loss > val_loss:\n",
        "      state={\n",
        "        \"model_state\":model.state_dict(),\n",
        "        \"optimizer_state\":optim.state_dict(),\n",
        "          }\n",
        "      torch.save(state,'/content/drive/MyDrive/ISBI-2016_pre-processed/models/U_Net_weights_ConvNext.pth') # ekhane notun weight er src ta korbi \n",
        "      best_loss = val_loss\n",
        "    train_loss_list = train_loss_list + [epoch_train_loss]\n",
        "    val_loss_list = val_loss_list + [epoch_val_loss]\n",
        "  #print(\"The model with the best performance has a score of :{:.4f}\".format(best_loss))\n",
        "  return model, train_loss_list, val_loss_list  \n",
        "\n",
        "\n",
        "def eval(model):#, criterion):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    val_loss=dice_val=iou_val=0.0\n",
        "    for _,data in enumerate(val_load):\n",
        "      image = data['image'].to(device, dtype=torch.float32)\n",
        "      mask_type = torch.float32 if n_classes == 1 else torch.long\n",
        "      mask = data['mask'].to(device, dtype=mask_type)\n",
        "      mask_gen = model(image)\n",
        "      loss = dice_coeff_loss(mask_gen, mask)\n",
        "      val_loss += loss.item()\n",
        "      iou_val += IoU_score(mask_gen,mask).item()\n",
        "      dice_val += dice_coeff(mask_gen,mask).item()\n",
        "  return val_loss, iou_val, dice_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EhovHMP7BQX"
      },
      "source": [
        "# Mask generation of entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wL206U2fP1NC",
        "outputId": "4c4f072c-ccb6-4410-9b17-9e3300cf900b"
      },
      "outputs": [],
      "source": [
        "\n",
        "model, train_loss_list, val_loss_list = train(model, epoch_n, optim)#, criterion)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "UNet_OpenSource.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
