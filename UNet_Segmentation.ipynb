{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhgLQ9PfNSt3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from skimage.io import imread \n",
        "from PIL import Image\n",
        "import csv\n",
        "import torch\n",
        "import copy\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils import data\n",
        "import torchvision.transforms as transf\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.transforms import RandomAdjustSharpness\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from torch import optim\n",
        "from torch.nn.modules.conv import ConvTranspose2d\n",
        "from torch.autograd import Function\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1vVTRnU5GBX"
      },
      "source": [
        "## Our dataset's path and preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi8ZjN9-KSRl",
        "outputId": "a50b0f90-5b12-4ee0-9fff-103194e522a7"
      },
      "source": [
        "Structure of dataset should be as following:\n",
        "\n",
        "--- /input\n",
        "------/image1.png\n",
        "------/image2.png\n",
        "------/image3.png  \n",
        "...\n",
        "\n",
        "--- /target\n",
        "------/mask1.png\n",
        "------/mask2.png\n",
        "------/mask3.png  \n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUVZape1oohP"
      },
      "source": [
        " Dataset pipeline \n",
        "--- ordered list of corresponding images and mask paths --- \n",
        "\n",
        "img_list --> ['image1.png', 'image2.png', 'image3.png',...]\n",
        "\n",
        "msk_list --> ['mask1.png', 'mask2.png', 'mask3.png',...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nfSrw5mFiDJ"
      },
      "outputs": [],
      "source": [
        "class SegDataset(data.Dataset):\n",
        "  \n",
        "  def __init__(self, img_list, msk_list, transform=None):\n",
        "    self.img_list = img_list\n",
        "    self.msk_list = msk_list\n",
        "    self.transforms = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n",
        "\n",
        "  @classmethod\n",
        "  def preprocess(self,pil_img, size):\n",
        "    # w,h = pil_img.size\n",
        "    # W,H = int(scale*w), int(scale*h)\n",
        "    pil_img = pil_img.resize((size,size))\n",
        "\n",
        "    img_nd = np.array(pil_img)\n",
        "\n",
        "    if len(img_nd.shape) == 2:\n",
        "      img_nd = np.expand_dims(img_nd, axis=2)\n",
        "\n",
        "    '''if tranforms are present paste them here'''\n",
        "\n",
        "    #HWC to CHW\n",
        "    img_trans = img_nd.transpose((2,0,1))\n",
        "    if img_trans.max() > 1:\n",
        "      img_trans = img_trans/225\n",
        "\n",
        "    return img_trans\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_ID = self.img_list[index]\n",
        "    target_ID = self.msk_list[index]\n",
        "\n",
        "    img = Image.open(input_ID)\n",
        "    msk = Image.open(target_ID)\n",
        "\n",
        "    ''' \n",
        "    assert img.size == msk.size, \\\n",
        "    f'Image and mask for {index} should be the same, but are {img.size} and {msk.size}'\n",
        "\n",
        "    # preprocessing\n",
        "    img = self.preprocess(img, 224)\n",
        "    msk = self.preprocess(msk, 216)\n",
        "    '''\n",
        "    return {\n",
        "        'image': torch.from_numpy(img).type(torch.FloatTensor),\n",
        "        'mask': torch.from_numpy(msk).type(torch.FloatTensor)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHTQVkuo5tMO"
      },
      "source": [
        "### Hyperparameter Tuning and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnSZRCggJQqU"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning\n",
        "batch_size_tr = 1\n",
        "batch_size_val = 1\n",
        "epoch_n = 200\n",
        "n_channels = 3\n",
        "n_classes = 1\n",
        "l_rate = 0.01\n",
        "'''\n",
        "img_scale = 1\n",
        "mask_threshold = 0.5\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2rn9A6ROcQK"
      },
      "outputs": [],
      "source": [
        "train_ds = SegDataset(input_tr, target_tr)#,transform=transforms_tr)\n",
        "val_ds = SegDataset(input_val, target_val)#,transform=transforms_val)\n",
        "# test_ds = ImageFolder('/content/drive/MyDrive/Lung_Carcinoma/data_folder_2/test/', transform=val_transform)\n",
        "train_load = DataLoader(dataset=train_ds, batch_size=batch_size_tr, shuffle=False, drop_last=False)\n",
        "val_load = DataLoader(dataset=val_ds, batch_size=batch_size_val, shuffle=False, drop_last=False)\n",
        "# test_load = DataLoader(dataset=test_ds, batch_size=batch_size_val, shuffle=True, drop_last=False)\n",
        "if torch.cuda.is_available():\n",
        "  device='cuda'\n",
        "else:\n",
        "  device='cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJTj1RFy6FS3"
      },
      "source": [
        "### Structure of U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfw_r6DwFR_L"
      },
      "outputs": [],
      "source": [
        "# Segmentation architecture\n",
        "# U-Net\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "    super().__init__()\n",
        "    if mid_channels is None:\n",
        "      mid_channels = out_channels\n",
        "    self.double_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, 3, 1),\n",
        "        nn.BatchNorm2d(mid_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(mid_channels, out_channels, 3, 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = nn.Sequential(\n",
        "        nn.MaxPool2d(2),\n",
        "        DoubleConv(in_channels, out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels, in_channels//2, 2, 2)\n",
        "    self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1=self.up(x1)\n",
        "    delta_W = x2.size()[3]-x1.size()[3]\n",
        "    delta_H = x2.size()[2]-x1.size()[2]\n",
        "    x1 = F.pad(x1,[delta_W//2,delta_W-delta_W//2,delta_H//2,delta_H-delta_H//2])\n",
        "    x = torch.cat([x2,x1],dim=1)\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class FinalConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_final = nn.Conv2d(in_channels, out_channels,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.conv_final(x)\n",
        "\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "  def __init__(self, in_channels, out_classes):\n",
        "    super(U_Net,self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_classes = out_classes\n",
        "\n",
        "    self.initial_conv = DoubleConv(in_channels, 64)\n",
        "    self.down1 = Down(64, 128)\n",
        "    self.down2 = Down(128, 256)\n",
        "    self.down3 = Down(256, 512)\n",
        "    self.down4 = Down(512, 1024)\n",
        "    self.up1 = Up(1024,512)\n",
        "    self.up2 = Up(512,256)\n",
        "    self.up3 = Up(256,128)\n",
        "    self.up4 = Up(128,64)\n",
        "    self.final = FinalConv(64, out_classes)\n",
        "    \n",
        "  \n",
        "  def forward(self,i):\n",
        "    i1 = self.initial_conv(i)\n",
        "    i2 = self.down1(i1)\n",
        "    i3 = self.down2(i2)\n",
        "    i4 = self.down3(i3)\n",
        "    i5 = self.down4(i4)\n",
        "    i = self.up1(i5,i4)\n",
        "    i = self.up2(i,i3)\n",
        "    i = self.up3(i,i2)\n",
        "    i = self.up4(i,i1)\n",
        "    i = self.final(i)\n",
        "    return i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIJ5l6vJ6Qgm"
      },
      "source": [
        "### Loss Functions (Dice Coeff and IOU Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx_FendLeJhV"
      },
      "outputs": [],
      "source": [
        "# loss functions\n",
        "\n",
        "'''Dice coeff'''\n",
        "\n",
        "class DiceCoeff(Function):\n",
        "    \"\"\"Dice coeff for individual examples\"\"\"\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        self.save_for_backward(input, target)\n",
        "        eps = 0.0001\n",
        "        self.inter = (input * target).sum(dim=(1, 2))\n",
        "        self.union = (input + target).sum(dim=(1, 2)) + eps -self.inter\n",
        "\n",
        "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
        "        return t.mean()\n",
        "\n",
        "    # This function has only a single output, so it gets only one gradient\n",
        "    def backward(self, grad_output):\n",
        "\n",
        "        input, target = self.saved_variables\n",
        "        grad_input = grad_target = None\n",
        "\n",
        "        if self.needs_input_grad[0]:\n",
        "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
        "                         / (self.union * self.union)\n",
        "        if self.needs_input_grad[1]:\n",
        "            grad_target = None\n",
        "\n",
        "        return grad_input, grad_target\n",
        "\n",
        "\n",
        "def dice_coeff(input, target):\n",
        "    \"\"\"Dice coeff for batches\"\"\"\n",
        "    if input.is_cuda:\n",
        "        s = torch.FloatTensor(1).cuda().zero_()\n",
        "    else:\n",
        "        s = torch.FloatTensor(1).zero_()\n",
        "\n",
        "    for i, c in enumerate(zip(input, target)):\n",
        "        s = s + DiceCoeff().forward(c[0], c[1])\n",
        "\n",
        "    return s \n",
        "\n",
        "### Evaluation metrics ###\n",
        "class Metric(object):\n",
        "    \"\"\"Base class for all metrics.\n",
        "    From: https://github.com/pytorch/tnt/blob/master/torchnet/meter/meter.py\n",
        "    \"\"\"\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "    def add(self):\n",
        "        pass\n",
        "\n",
        "    def value(self):\n",
        "        pass\n",
        "\n",
        "'''Confusion Matrix'''\n",
        "\n",
        "class ConfusionMatrix(Metric):\n",
        "    \"\"\"Constructs a confusion matrix for a multi-class classification problems.\n",
        "    Does not support multi-label, multi-class problems.\n",
        "    Keyword arguments:\n",
        "    - num_classes (int): number of classes in the classification problem.\n",
        "    - normalized (boolean, optional): Determines whether or not the confusion\n",
        "    matrix is normalized or not. Default: False.\n",
        "    Modified from: https://github.com/pytorch/tnt/blob/master/torchnet/meter/confusionmeter.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, normalized=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conf = np.ndarray((num_classes, num_classes), dtype=np.int64)\n",
        "        self.normalized = normalized\n",
        "        self.num_classes = num_classes\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.conf.fill(0)\n",
        "\n",
        "    def add(self, predicted, target):\n",
        "        \"\"\"Computes the confusion matrix\n",
        "        The shape of the confusion matrix is K x K, where K is the number\n",
        "        of classes.\n",
        "        Keyword arguments:\n",
        "        - predicted (Tensor or numpy.ndarray): Can be an N x K tensor/array of\n",
        "        predicted scores obtained from the model for N examples and K classes,\n",
        "        or an N-tensor/array of integer values between 0 and K-1.\n",
        "        - target (Tensor or numpy.ndarray): Can be an N x K tensor/array of\n",
        "        ground-truth classes for N examples and K classes, or an N-tensor/array\n",
        "        of integer values between 0 and K-1.\n",
        "        \"\"\"\n",
        "        # If target and/or predicted are tensors, convert them to numpy arrays\n",
        "        if torch.is_tensor(predicted):\n",
        "            predicted = predicted.cpu().numpy()\n",
        "        if torch.is_tensor(target):\n",
        "            target = target.cpu().numpy()\n",
        "\n",
        "        assert predicted.shape[0] == target.shape[0], \\\n",
        "            'number of targets and predicted outputs do not match'\n",
        "\n",
        "        if np.ndim(predicted) != 1:\n",
        "            assert predicted.shape[1] == self.num_classes, \\\n",
        "                'number of predictions does not match size of confusion matrix'\n",
        "            predicted = np.argmax(predicted, 1)\n",
        "        else:\n",
        "            assert (predicted.max() < self.num_classes) and (predicted.min() >= 0), \\\n",
        "                'predicted values are not between 0 and k-1'\n",
        "\n",
        "        if np.ndim(target) != 1:\n",
        "            assert target.shape[1] == self.num_classes, \\\n",
        "                'Onehot target does not match size of confusion matrix'\n",
        "            assert (target >= 0).all() and (target <= 1).all(), \\\n",
        "                'in one-hot encoding, target values should be 0 or 1'\n",
        "            assert (target.sum(1) == 1).all(), \\\n",
        "                'multi-label setting is not supported'\n",
        "            target = np.argmax(target, 1)\n",
        "        else:\n",
        "            assert (target.max() < self.num_classes) and (target.min() >= 0), \\\n",
        "                'target values are not between 0 and k-1'\n",
        "\n",
        "        # hack for bincounting 2 arrays together\n",
        "        x = predicted + self.num_classes * target\n",
        "        bincount_2d = np.bincount(\n",
        "            x.astype(np.int64), minlength=self.num_classes**2)\n",
        "        assert bincount_2d.size == self.num_classes**2\n",
        "        conf = bincount_2d.reshape((self.num_classes, self.num_classes))\n",
        "\n",
        "        self.conf += conf\n",
        "\n",
        "    def value(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            Confustion matrix of K rows and K columns, where rows corresponds\n",
        "            to ground-truth targets and columns corresponds to predicted\n",
        "            targets.\n",
        "        \"\"\"\n",
        "        if self.normalized:\n",
        "            conf = self.conf.astype(np.float32)\n",
        "            return conf / conf.sum(1).clip(min=1e-12)[:, None]\n",
        "        else:\n",
        "            return self.conf\n",
        "\n",
        "\n",
        "\n",
        "'''IoU'''\n",
        "\n",
        "class IoU(Metric):\n",
        "    \"\"\"Computes the intersection over union (IoU) per class and corresponding\n",
        "    mean (mIoU).\n",
        "    Intersection over union (IoU) is a common evaluation metric for semantic\n",
        "    segmentation. The predictions are first accumulated in a confusion matrix\n",
        "    and the IoU is computed from it as follows:\n",
        "        IoU = true_positive / (true_positive + false_positive + false_negative).\n",
        "    Keyword arguments:\n",
        "    - num_classes (int): number of classes in the classification problem\n",
        "    - normalized (boolean, optional): Determines whether or not the confusion\n",
        "    matrix is normalized or not. Default: False.\n",
        "    - ignore_index (int or iterable, optional): Index of the classes to ignore\n",
        "    when computing the IoU. Can be an int, or any iterable of ints.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, normalized=False, ignore_index=None):\n",
        "        super().__init__()\n",
        "        self.conf_metric = ConfusionMatrix(num_classes, normalized)\n",
        "\n",
        "        if ignore_index is None:\n",
        "            self.ignore_index = None\n",
        "        elif isinstance(ignore_index, int):\n",
        "            self.ignore_index = (ignore_index,)\n",
        "        else:\n",
        "            try:\n",
        "                self.ignore_index = tuple(ignore_index)\n",
        "            except TypeError:\n",
        "                raise ValueError(\"'ignore_index' must be an int or iterable\")\n",
        "\n",
        "    def reset(self):\n",
        "        self.conf_metric.reset()\n",
        "\n",
        "    def add(self, predicted, target):\n",
        "        \"\"\"Adds the predicted and target pair to the IoU metric.\n",
        "        Keyword arguments:\n",
        "        - predicted (Tensor): Can be a (N, K, H, W) tensor of\n",
        "        predicted scores obtained from the model for N examples and K classes,\n",
        "        or (N, H, W) tensor of integer values between 0 and K-1.\n",
        "        - target (Tensor): Can be a (N, K, H, W) tensor of\n",
        "        target scores for N examples and K classes, or (N, H, W) tensor of\n",
        "        integer values between 0 and K-1.\n",
        "        \"\"\"\n",
        "        # Dimensions check\n",
        "        assert predicted.size(0) == target.size(0), \\\n",
        "            'number of targets and predicted outputs do not match'\n",
        "        assert predicted.dim() == 3 or predicted.dim() == 4, \\\n",
        "            \"predictions must be of dimension (N, H, W) or (N, K, H, W)\"\n",
        "        assert target.dim() == 3 or target.dim() == 4, \\\n",
        "            \"targets must be of dimension (N, H, W) or (N, K, H, W)\"\n",
        "\n",
        "        # If the tensor is in categorical format convert it to integer format\n",
        "        if predicted.dim() == 4:\n",
        "            _, predicted = predicted.max(1)\n",
        "        if target.dim() == 4:\n",
        "            _, target = target.max(1)\n",
        "\n",
        "        self.conf_metric.add(predicted.view(-1), target.view(-1))\n",
        "\n",
        "    def value(self):\n",
        "        \"\"\"Computes the IoU and mean IoU.\n",
        "        The mean computation ignores NaN elements of the IoU array.\n",
        "        Returns:\n",
        "            Tuple: (IoU, mIoU). The first output is the per class IoU,\n",
        "            for K classes it's numpy.ndarray with K elements. The second output,\n",
        "            is the mean IoU.\n",
        "        \"\"\"\n",
        "        conf_matrix = self.conf_metric.value()\n",
        "        if self.ignore_index is not None:\n",
        "            conf_matrix[:, self.ignore_index] = 0\n",
        "            conf_matrix[self.ignore_index, :] = 0\n",
        "        true_positive = np.diag(conf_matrix)\n",
        "        false_positive = np.sum(conf_matrix, 0) - true_positive\n",
        "        false_negative = np.sum(conf_matrix, 1) - true_positive\n",
        "\n",
        "        # Just in case we get a division by 0, ignore/hide the error\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            iou = true_positive / (true_positive + false_positive + false_negative)\n",
        "\n",
        "        return iou, np.nanmean(iou)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6IK7r5j630X"
      },
      "source": [
        "### Model specifications and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBpS3FgJtikn"
      },
      "outputs": [],
      "source": [
        "model = U_Net(n_channels, n_classes)\n",
        "'''state=torch.load('/content/drive/MyDrive/PH2/model_wts/U_Net_weights_1.pth') # ekhane previous weight ta src korbi \n",
        "model.load_state_dict(state['model_state'])'''\n",
        "model = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "#DiceCoeff()\n",
        "#iou = IoU(num_classes=2)\n",
        "criterion = criterion.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), l_rate)\n",
        "'''optim.load_state_dict(state['optimizer_state'])'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEqb5JGqF4_j"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "def train(model, epoch_n, optim,criterion):\n",
        "  best_loss=1000.0 \n",
        "  train_loss_list = []\n",
        "  val_loss_list = []\n",
        "  for epoch in range(epoch_n):\n",
        "    model.train()\n",
        "    train_loss=miou=total=dice_score=0.0\n",
        "    for _,data in enumerate(train_load):\n",
        "      image = data['image'].to(device, dtype=torch.float32)\n",
        "      mask_type = torch.float32 if n_classes == 1 else torch.long\n",
        "      mask = data['mask'].to(device, dtype=mask_type)\n",
        "      with torch.set_grad_enabled(True):\n",
        "        mask_gen = model(image)\n",
        "        loss = criterion(mask_gen,mask)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "      optim.zero_grad()\n",
        "      train_loss += loss.item()\n",
        "      total += mask.size(0)\n",
        "      # iou.add(mask_gen, mask)\n",
        "      # _ ,miou_temp =  iou.value()\n",
        "      # miou += miou_temp\n",
        "      #dice_score += dice_coeff(mask_gen,mask).item()\n",
        "    val_loss, dice_score_val = eval(model, criterion)\n",
        "    epoch_train_loss = train_loss/len(train_ds)\n",
        "    print(\"Epoch: {}\".format(epoch+1))\n",
        "    print('-'*10)\n",
        "    print('Train Loss: {:.4f}'.format(epoch_train_loss))\n",
        "    epoch_val_loss = val_loss/len(val_ds)\n",
        "    print('Val Loss: {:.4f}'.format(epoch_val_loss))\n",
        "    print('\\n')\n",
        "    # iou_score = miou*100/total\n",
        "    '''print('Dice score train: {:.4f}'.format(dice_score))\n",
        "    print('\\n')\n",
        "    print('Dice score val: {:.4f}'.format(dice_score_val))\n",
        "    print('\\n')'''\n",
        "    '''plt.imshow(mask_gen.cpu().detach().numpy()[-3][0])\n",
        "    plt.imshow(mask.cpu().detach().numpy()[-1].transpose((1,2,0)))\n",
        "    _, axarr = plt.subplots(1,3)\n",
        "    print(image.cpu().detach().numpy()[-1].shape)\n",
        "    axarr[2] = plt.imshow(mask_gen.cpu().detach().numpy()[-1][0])\n",
        "    axarr[1] = plt.imshow(mask.cpu().detach().numpy()[-1][0].transpose((1,2,0)))\n",
        "    axarr[0] = plt.imshow(image.cpu().detach().numpy()[-3].transpose((1,2,0)))\n",
        "    input()'''\n",
        "    if epoch == epoch_n:\n",
        "      best_loss = epoch_val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      state={\n",
        "          \"model_state\":model.state_dict(),\n",
        "          \"optimizer_state\":optim.state_dict(),\n",
        "            }\n",
        "      torch.save(state,'/content/drive/MyDrive/PH2/model_wts/U_Net_weights_1.pth') \n",
        "    train_loss_list = train_loss_list + [epoch_train_loss]\n",
        "    val_loss_list = val_loss_list + [epoch_val_loss]\n",
        "  model = model.load_state_dict(best_model_wts)\n",
        "  print(\"The model with the best performance has a score of :{:.4f}\".format(best_loss))\n",
        "  return model, train_loss_list, val_loss_list  \n",
        "\n",
        "\n",
        "def eval(model, criterion):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    val_loss=dice_score=0.0\n",
        "    for _,data in enumerate(val_load):\n",
        "      image = data['image'].to(device, dtype=torch.float32)\n",
        "      mask_type = torch.float32 if n_classes == 1 else torch.long\n",
        "      mask = data['mask'].to(device, dtype=mask_type)\n",
        "      mask_gen = model(image)\n",
        "      loss = criterion(mask_gen, mask)\n",
        "      val_loss += loss.item()\n",
        "      dice_score += dice_coeff(mask_gen,mask).item()\n",
        "  return val_loss, dice_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL206U2fP1NC"
      },
      "outputs": [],
      "source": [
        "model, train_loss_list, val_loss_list = train(model, epoch_n, optim, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EhovHMP7BQX"
      },
      "source": [
        "### Mask generation of entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bk5sJ32VUZI"
      },
      "outputs": [],
      "source": [
        "def eval(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # val_loss=dice_score=0.0\n",
        "    for i,data in enumerate(val_load):\n",
        "      image = data['image'].to(device, dtype=torch.float32)\n",
        "      mask_type = torch.float32 if n_classes == 1 else torch.long\n",
        "      mask = data['mask'].to(device, dtype=mask_type)\n",
        "      mask_gen = model(image)\n",
        "      path = input_val[i]\n",
        "      file_name = path[-10:-4]\n",
        "      for element, class_t in class_list:\n",
        "        if element == file_name:\n",
        "          class_type = class_t\n",
        "      if class_type == '0':\n",
        "        plt.imsave(path[:-17]+'_classifier/common_nevus/'+path[-10:], mask_gen[0][0].cpu().detach().numpy())\n",
        "      if class_type == '1':\n",
        "        plt.imsave(path[:-17]+'_classifier/atypical_nevus/'+path[-10:], mask_gen[0][0].cpu().detach().numpy())\n",
        "      if class_type == '2':\n",
        "        plt.imsave(path[:-17]+'_classifier/melanoma/'+path[-10:], mask_gen[0][0].cpu().detach().numpy())\n",
        "      # loss = criterion(mask_gen, mask)\n",
        "      # val_loss += loss.item()\n",
        "      # dice_score += dice_coeff(mask_gen,mask).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBnS2kEOcJ39"
      },
      "outputs": [],
      "source": [
        "eval(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "UNet_OpenSource.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
